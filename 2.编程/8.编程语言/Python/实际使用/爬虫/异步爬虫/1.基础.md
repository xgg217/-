# 高性能异步爬虫

## 目的

+ 在爬虫中使用异步实现高性能的数据爬取操作

## 异步爬虫的方式

+ 多线程，多进程

  + 好处：可以为相关阻塞的操作单独开启线程或者进程
  + 弊端：无法无限制的开启多线程或多进程

+ 线程池、进程池（适当的使用）

  + 好处：可以减低系统对进程或线程创建和销毁的频率，从而降低系统开销
  + 弊端：池中线程或进程的数量有上限

+ 单线程 + 异步协程 **推荐使用**

## 示例

+ 常规使用

  ```py
  import requests,time
  arr = [
      "http://www.bmhm.cc/uploads/allimg/mlxsj/qhta4ghj5tm.jpg",
      "http://www.bmhm.cc/uploads/allimg/mlxsj/dx5djd10tgx.jpg",
      "http://www.bmhm.cc/uploads/allimg/mlxsj/2iausqvvg4z.jpg",
      "http://www.bmhm.cc/uploads/allimg/mlxsj/4pzabjh1sn2.jpg",
      "http://www.bmhm.cc/uploads/allimg/mlxsj/i433qwgshjm.jpg",
      "http://www.bmhm.cc/uploads/allimg/mlxsj/rjaxhmvmij2.jpg",
      "http://www.bmhm.cc/uploads/allimg/mlxsj/tppbfsj2zw3.jpg",
  ]

  headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36'
  }

  def get_content(url):
    print('正在爬取',url)
    # get 是一个阻塞的方法
    res = requests.get(url=url,headers=headers)
    if res.status_code == 200:
        return res.content

  def parse_content(content):
      time.sleep(5)
      print('响应数据的长度', len(content))

  for item in arr:
      content = get_content(item)
      parse_content(content)
  ```
